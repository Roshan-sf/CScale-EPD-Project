{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lZJeGim1LH9Ou0pqhXwSrlMw2y72UV\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = \"https://buildingtransparency.org/api/rest-auth/login\"\n",
    "\n",
    "querystring = {\"tokenless\":\"false\"}\n",
    "\n",
    "payload = {\n",
    "    \"username\": os.getenv(\"OPENEPD_USER\"),\n",
    "    \"password\": os.getenv(\"OPENEPD_PW\")\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Accept\": \"application/json\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers, params=querystring)\n",
    "\n",
    "response_data = response.json()\n",
    "\n",
    "#print(response_data)\n",
    "\n",
    "auth_key = response.json()['key']\n",
    "\n",
    "print(auth_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \"+auth_key\n",
    "}\n",
    "\n",
    "#ndustry_epd_url = \"https://buildingtransparency.org/api/industry_epds\"\n",
    "product_epd_url = \"https://buildingtransparency.org/api/epds\"\n",
    "\n",
    "querystring = {\"page_size\":\"250\"}\n",
    "\n",
    "#indus_response = requests.get(industry_epd_url, headers=headers, params=querystring)\n",
    "prod_response = requests.get(product_epd_url, headers=headers, params=querystring)\n",
    "\n",
    "#indus_results = indus_response.json()\n",
    "prod_results = prod_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "ec3rp05b\n"
     ]
    }
   ],
   "source": [
    "#prod_results[93]\n",
    "lcia = list(prod_results[93]['pcr']['lcia_requirements'].keys())[0]\n",
    "print(type(lcia))\n",
    "print(prod_results[48]['open_xpd_uuid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EF 3.0': {'gwp': {'A1A2A3': {'mean': 133.0,\n",
       "    'unit': 'kgCO2e',\n",
       "    'rsd': 0.28879058156387305,\n",
       "    'dist': 'log-normal'},\n",
       "   'A1': None,\n",
       "   'A2': None,\n",
       "   'A3': None,\n",
       "   'A4': None,\n",
       "   'A5': None,\n",
       "   'B1': None,\n",
       "   'B1_years': None,\n",
       "   'B2': None,\n",
       "   'B2_years': None,\n",
       "   'B3': None,\n",
       "   'B3_years': None,\n",
       "   'B4': None,\n",
       "   'B4_years': None,\n",
       "   'B5': None,\n",
       "   'B5_years': None,\n",
       "   'B6': None,\n",
       "   'B6_years': None,\n",
       "   'B7': None,\n",
       "   'B7_years': None,\n",
       "   'C1': None,\n",
       "   'C2': None,\n",
       "   'C3': None,\n",
       "   'C4': None,\n",
       "   'D': None,\n",
       "   'C_scenarios': None}}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "impact_info_url = \"https://openepd.buildingtransparency.org/api/epds/\"+\"ec3rp05b\"\n",
    "\n",
    "response_impact = requests.get(impact_info_url, headers=headers)\n",
    "resp = response_impact.json()\n",
    "# print(resp['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'])\n",
    "# print(resp['impacts'][lcia]['gwp']['C2'])\n",
    "# print(resp['impacts'][lcia]['gwp']['C3'])\n",
    "# print(resp['impacts'][lcia]['gwp']['C4'])\n",
    "# print(resp['impacts'][lcia]['odp'])\n",
    "\n",
    "resp['impacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product EPD Pages:  722\n"
     ]
    }
   ],
   "source": [
    "#total_pages = int(indus_response.headers['X-Total-Pages'])\n",
    "total_pages2 = int(prod_response.headers['X-Total-Pages'])\n",
    "\n",
    "#print('Industry EPD Pages: ', total_pages)\n",
    "print('Product EPD Pages: ', total_pages2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully completed page 1\n",
      "successfully completed page 2\n"
     ]
    }
   ],
   "source": [
    "product_epds = []\n",
    "\n",
    "for i in range(0,2):\n",
    "        querystring = {\n",
    "                \"page_number\": i+1,\n",
    "                \"page_size\":\"250\"}\n",
    "        response = requests.get(product_epd_url, headers=headers, params=querystring)\n",
    "        epd_data = response.json()\n",
    "        for epd in epd_data:\n",
    "                product_epds.append(epd)\n",
    "        print(\"successfully completed page \"+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully completed page 1\n",
      "successfully completed page 2\n"
     ]
    }
   ],
   "source": [
    "EC3_epds = []\n",
    "\n",
    "for i in range(0,2):\n",
    "        querystring = {\n",
    "                \"page_number\": i+1,\n",
    "                \"page_size\":\"250\"}\n",
    "        response = requests.get(product_epd_url, headers=headers, params=querystring)\n",
    "        epd_data = response.json()\n",
    "        for epd in epd_data:\n",
    "                EC3_epds.append(epd)\n",
    "        print(\"successfully completed page \"+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('EC3_epds.json', 'w') as file:\n",
    "    json.dump(EC3_epds, file)\n",
    "\n",
    "print(\"Data saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "epd_impacts = []\n",
    "impact_info_url = \"https://openepd.buildingtransparency.org/api/epds/\"\n",
    "\n",
    "for i in range(0, 266):\n",
    "    xpdID = EC3_epds[i]['open_xpd_uuid']\n",
    "    \n",
    "    while True:\n",
    "        response_impact = requests.get(impact_info_url + xpdID, headers=headers)\n",
    "        if response_impact.status_code == 200:\n",
    "            epd_impacts.append(response_impact.json())\n",
    "            break\n",
    "        elif response_impact.status_code == 429:  # Throttling status code\n",
    "            error_details = response_impact.json()\n",
    "            wait_time = int(error_details.get('detail', '').split()[-2])\n",
    "            print(f\"Throttled on json {i}, Waiting for {wait_time} seconds\")\n",
    "            time.sleep(wait_time)\n",
    "        else:\n",
    "            print(f\"Error: {response_impact.status_code}\")\n",
    "            break\n",
    "    \n",
    "    if i % 25 == 0:\n",
    "        print(f'done with impact {i}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to epd_impacts.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Save epd_impacts to a JSON file\n",
    "with open('epd_impacts.json', 'w') as file:\n",
    "    json.dump(epd_impacts, file)\n",
    "\n",
    "print(\"Data saved to epd_impacts.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load epd_impacts from the JSON file\n",
    "with open('epd_impacts.json', 'r') as file:\n",
    "    epd_impacts = json.load(file)\n",
    "\n",
    "print(\"Data loaded from epd_impacts.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epd_impacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impact_data = {\n",
    "\n",
    "        f\"{lcia}\": {\n",
    "            \"gwp_total\": {\n",
    "            \"A1_A3\": epd_impacts[17]['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'],\n",
    "            \"C2\": epd_impacts[0]['impacts'][lcia]['gwp']['C2'],\n",
    "            \"C3\": epd_impacts[0]['impacts'][lcia]['gwp']['C3'],\n",
    "            \"C4\": epd_impacts[0]['impacts'][lcia]['gwp']['C4'],\n",
    "            \"D1\": epd_impacts[0]['impacts'][lcia]['gwp']['D']\n",
    "            },\n",
    "        }\n",
    "}\n",
    "\n",
    "print(impact_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_split(s):\n",
    "    if s is None:\n",
    "        return \"data not provided\", \"data not provided\"\n",
    "    parts = s.split(' ', 1)\n",
    "    \n",
    "    magnitude = float(parts[0])\n",
    "    unit = parts[1]\n",
    "    \n",
    "    return magnitude, unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json #0 is done\n",
      "json #1 is done\n",
      "json #2 is done\n",
      "json #3 is done\n",
      "json #4 is done\n",
      "json #5 is done\n",
      "json #6 is done\n",
      "json #7 is done\n",
      "json #8 is done\n",
      "json #9 is done\n",
      "json #10 is done\n",
      "json #11 is done\n",
      "json #12 is done\n",
      "json #13 is done\n",
      "json #14 is done\n",
      "json #15 is done\n",
      "json #16 is done\n",
      "json #17 is done\n",
      "json #18 is done\n",
      "json #19 is done\n",
      "json #20 is done\n",
      "json #21 is done\n",
      "json #22 is done\n",
      "json #23 is done\n",
      "json #24 is done\n",
      "json #25 is done\n",
      "json #26 is done\n",
      "json #27 is done\n",
      "json #28 is done\n",
      "json #29 is done\n",
      "json #30 is done\n",
      "json #31 is done\n",
      "json #32 is done\n",
      "json #33 is done\n",
      "json #34 is done\n",
      "json #35 is done\n",
      "json #36 is done\n",
      "json #37 is done\n",
      "json #38 is done\n",
      "json #39 is done\n",
      "json #40 is done\n",
      "json #41 is done\n",
      "json #42 is done\n",
      "json #43 is done\n",
      "json #44 is done\n",
      "json #45 is done\n",
      "json #46 is done\n",
      "json #47 is done\n",
      "json #48 is done\n",
      "json #49 is done\n",
      "json #50 is done\n",
      "json #51 is done\n",
      "json #52 is done\n",
      "json #53 is done\n",
      "json #54 is done\n",
      "json #55 is done\n",
      "json #56 is done\n",
      "json #57 is done\n",
      "json #58 is done\n",
      "json #59 is done\n",
      "Skipping index 60 due to missing or invalid lcia_requirements: lcia_requirements is None\n",
      "json #61 is done\n",
      "json #62 is done\n",
      "json #63 is done\n",
      "json #64 is done\n",
      "json #65 is done\n",
      "json #66 is done\n",
      "json #67 is done\n",
      "json #68 is done\n",
      "json #69 is done\n",
      "json #70 is done\n",
      "json #71 is done\n",
      "json #72 is done\n",
      "json #73 is done\n",
      "json #74 is done\n",
      "json #75 is done\n",
      "json #76 is done\n",
      "json #77 is done\n",
      "json #78 is done\n",
      "json #79 is done\n",
      "json #80 is done\n",
      "json #81 is done\n",
      "json #82 is done\n",
      "json #83 is done\n",
      "json #84 is done\n",
      "json #85 is done\n",
      "json #86 is done\n",
      "json #87 is done\n",
      "json #88 is done\n",
      "json #89 is done\n",
      "json #90 is done\n",
      "json #91 is done\n",
      "json #92 is done\n",
      "json #93 is done\n",
      "json #94 is done\n",
      "json #95 is done\n",
      "json #96 is done\n",
      "json #97 is done\n",
      "json #98 is done\n",
      "json #99 is done\n",
      "json #100 is done\n",
      "json #101 is done\n",
      "json #102 is done\n",
      "json #103 is done\n",
      "json #104 is done\n",
      "json #105 is done\n",
      "json #106 is done\n",
      "json #107 is done\n",
      "json #108 is done\n",
      "json #109 is done\n",
      "json #110 is done\n",
      "json #111 is done\n",
      "json #112 is done\n",
      "json #113 is done\n",
      "json #114 is done\n",
      "json #115 is done\n",
      "json #116 is done\n",
      "json #117 is done\n",
      "json #118 is done\n",
      "json #119 is done\n",
      "json #120 is done\n",
      "json #121 is done\n",
      "json #122 is done\n",
      "json #123 is done\n",
      "json #124 is done\n",
      "json #125 is done\n",
      "json #126 is done\n",
      "json #127 is done\n",
      "json #128 is done\n",
      "json #129 is done\n",
      "json #130 is done\n",
      "json #131 is done\n",
      "json #132 is done\n",
      "json #133 is done\n",
      "json #134 is done\n",
      "json #135 is done\n",
      "json #136 is done\n",
      "json #137 is done\n",
      "json #138 is done\n",
      "json #139 is done\n",
      "json #140 is done\n",
      "json #141 is done\n",
      "json #142 is done\n",
      "json #143 is done\n",
      "json #144 is done\n",
      "json #145 is done\n",
      "json #146 is done\n",
      "json #147 is done\n",
      "json #148 is done\n",
      "json #149 is done\n",
      "json #150 is done\n",
      "json #151 is done\n",
      "json #152 is done\n",
      "json #153 is done\n",
      "json #154 is done\n",
      "json #155 is done\n",
      "json #156 is done\n",
      "json #157 is done\n",
      "json #158 is done\n",
      "json #159 is done\n",
      "json #160 is done\n",
      "json #161 is done\n",
      "json #162 is done\n",
      "json #163 is done\n",
      "json #164 is done\n",
      "json #165 is done\n",
      "json #166 is done\n",
      "json #167 is done\n",
      "json #168 is done\n",
      "json #169 is done\n",
      "json #170 is done\n",
      "json #171 is done\n",
      "json #172 is done\n",
      "json #173 is done\n",
      "json #174 is done\n",
      "json #175 is done\n",
      "json #176 is done\n",
      "json #177 is done\n",
      "json #178 is done\n",
      "json #179 is done\n",
      "json #180 is done\n",
      "json #181 is done\n",
      "json #182 is done\n",
      "json #183 is done\n",
      "json #184 is done\n",
      "json #185 is done\n",
      "json #186 is done\n",
      "json #187 is done\n",
      "json #188 is done\n",
      "json #189 is done\n",
      "json #190 is done\n",
      "json #191 is done\n",
      "json #192 is done\n",
      "json #193 is done\n",
      "json #194 is done\n",
      "json #195 is done\n",
      "json #196 is done\n",
      "json #197 is done\n",
      "json #198 is done\n",
      "json #199 is done\n",
      "json #200 is done\n",
      "json #201 is done\n",
      "json #202 is done\n",
      "json #203 is done\n",
      "json #204 is done\n",
      "json #205 is done\n",
      "json #206 is done\n",
      "json #207 is done\n",
      "json #208 is done\n",
      "json #209 is done\n",
      "json #210 is done\n",
      "json #211 is done\n",
      "json #212 is done\n",
      "json #213 is done\n",
      "json #214 is done\n",
      "json #215 is done\n",
      "json #216 is done\n",
      "json #217 is done\n",
      "json #218 is done\n",
      "json #219 is done\n",
      "json #220 is done\n",
      "json #221 is done\n",
      "json #222 is done\n",
      "json #223 is done\n",
      "json #224 is done\n",
      "json #225 is done\n",
      "json #226 is done\n",
      "json #227 is done\n",
      "json #228 is done\n",
      "json #229 is done\n",
      "json #230 is done\n",
      "json #231 is done\n",
      "json #232 is done\n",
      "json #233 is done\n",
      "json #234 is done\n",
      "json #235 is done\n",
      "json #236 is done\n",
      "json #237 is done\n",
      "json #238 is done\n",
      "json #239 is done\n",
      "json #240 is done\n",
      "json #241 is done\n",
      "json #242 is done\n",
      "json #243 is done\n",
      "json #244 is done\n",
      "json #245 is done\n",
      "json #246 is done\n",
      "json #247 is done\n",
      "json #248 is done\n",
      "json #249 is done\n",
      "json #250 is done\n",
      "json #251 is done\n",
      "json #252 is done\n",
      "json #253 is done\n",
      "json #254 is done\n",
      "json #255 is done\n",
      "json #256 is done\n",
      "json #257 is done\n",
      "json #258 is done\n",
      "json #259 is done\n",
      "All data saved to epds.json\n",
      "All error data saved to epds.json\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "\n",
    "#category = ['GWP-total','GWP-biogenic','GWP-fossil','GWP-IOBC']\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \"+auth_key\n",
    "}\n",
    "\n",
    "product_epd_url = \"https://buildingtransparency.org/api/epds\"\n",
    "impact_info_url = \"https://openepd.buildingtransparency.org/api/epds/\"\n",
    "\n",
    "EPDs = []\n",
    "#EC3_epds = []\n",
    "product_epds = []\n",
    "error_epds = []\n",
    "none = \"Unmapped\"\n",
    "page = 0\n",
    "\n",
    "for x in range(0,260):\n",
    "    # if x % 250 == 0 or page == 0:\n",
    "    #     page += 1\n",
    "    #     EC3_epds.extend(get_page(page))\n",
    "\n",
    "\n",
    "    date_validity_ends_str = EC3_epds[x]['date_validity_ends']\n",
    "    #date_validity_ends = datetime.strptime(date_validity_ends_str, '%Y-%m-%d')\n",
    "\n",
    "    #if date_validity_ends < datetime.now():\n",
    "        #print(f\"EPD {x} expired, skipping...\")\n",
    "        #continue\n",
    "\n",
    "    # xpdID = EC3_epds[x]['open_xpd_uuid']\n",
    "    # response_impact = requests.get(impact_info_url+xpdID, headers=headers)\n",
    "    # impact = response_impact.json()\n",
    "\n",
    "    material_data = {} \n",
    "\n",
    "    ############################### DATA PATHS #################################\n",
    "    #lcia = list(EC3_epds[x]['pcr']['lcia_requirements'].keys())[0]\n",
    "\n",
    "    try:\n",
    "        lcia_requirements = EC3_epds[x]['pcr']['lcia_requirements']\n",
    "        if lcia_requirements is None:\n",
    "            raise ValueError(\"lcia_requirements is None\")\n",
    "\n",
    "        lcia = list(lcia_requirements.keys())[0]\n",
    "    except (AttributeError, ValueError) as e:\n",
    "        print(f\"Skipping index {x} due to missing or invalid lcia_requirements: {e}\")\n",
    "        error_epds.append(f'EC3_epd.json {x} lcia key error')\n",
    "        continue\n",
    "\n",
    "    transport_dist, transport_unit = string_split(EC3_epds[x]['category']['default_distance'])\n",
    "    dens, dens_unit = string_split(EC3_epds[x]['density'])\n",
    "    mass, mass_unit = string_split(EC3_epds[x]['category']['mass_per_declared_unit'])\n",
    "    \n",
    "\n",
    "    material_data['material_id'] = f'EC3_{EC3_epds[x]['category']['id']}'\n",
    "    material_data.update({'validity':{'gte':EC3_epds[x]['category']['created_on'], 'lte':date_validity_ends_str}})\n",
    "    material_data.update({'display_name':EC3_epds[x]['category']['display_name']})\n",
    "    material_data.update({\"source\": \"EC3 Product Specific EPDs\"})\n",
    "    material_data.update({'declared_unit':EC3_epds[x]['category']['declared_unit']})\n",
    "    material_data.update({'A4_transportation':{'mode':EC3_epds[x]['category']['default_transport_mode'], 'distance':{'qty':transport_dist, 'unit':transport_unit}}})\n",
    "    material_data.update({'service_life':EC3_epds[x]['reference_service_life']})\n",
    "    material_data.update({'waste_rate':none})\n",
    "    material_data.update({'density':{'qty':dens, 'unit':dens_unit}})\n",
    "    material_data.update({'item_mass':{'qty':mass, 'unit':mass_unit}})\n",
    "\n",
    "    # Add link to epd\n",
    "\n",
    "    # try:\n",
    "    #     material_data.update({'impacts':{lcia:{'gwp_total':{'A1_A3':epd_impacts['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'], 'C2':epd_impacts['impacts'][lcia]['gwp']['C2'], 'C3':epd_impacts['impacts'][lcia]['gwp']['C3'], 'C4':epd_impacts['impacts'][lcia]['gwp']['C4'], 'D':epd_impacts['impacts'][lcia]['gwp']['D']}}}})\n",
    "    # except KeyError:\n",
    "        # print(f'Key error on json #{x}')\n",
    "        # message = f'json {x} key error'\n",
    "        # error_epds.append(message)\n",
    "        # material_data.update({'characteristics':message})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    desc = EC3_epds[x]['category']['description']\n",
    "    pcr_name = EC3_epds[x]['pcr']['name']\n",
    "    pcr_id = EC3_epds[x]['pcr']['id']\n",
    "    short_link = EC3_epds[x]['pcr']['short_link']\n",
    "    created_on = EC3_epds[x]['category']['created_on']\n",
    "\n",
    "    thckqty = EC3_epds[x]['thickness']\n",
    "    thckU = EC3_epds[x]['thickness_per_declared_unit']\n",
    "\n",
    "\n",
    "    dens = EC3_epds[x]['density']\n",
    "    sdens = EC3_epds[x]['specific_density']\n",
    "\n",
    "    try:\n",
    "        impact_data = {\n",
    "            f\"{lcia}\": {\n",
    "                \"gwp_total\": {\n",
    "                    \"A1_A3\":{'mean': epd_impacts[x]['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'], 'unit': epd_impacts[x]['impacts'][lcia]['gwp'][\"A1A2A3\"]['unit']},\n",
    "                    \"C2\": epd_impacts[x]['impacts'][lcia]['gwp']['C2'],\n",
    "                    \"C3\": epd_impacts[x]['impacts'][lcia]['gwp']['C3'],\n",
    "                    \"C4\": epd_impacts[x]['impacts'][lcia]['gwp']['C4'],\n",
    "                    \"D1\": epd_impacts[x]['impacts'][lcia]['gwp']['D']\n",
    "                }\n",
    "            },\n",
    "            \"characteristics\": {}\n",
    "        }\n",
    "        \n",
    "    except KeyError:\n",
    "        lcia = 'Unknown LCIA'\n",
    "        error_epds.append(f'impact json {x} lcia error: \"unknown LCIA\" key')\n",
    "\n",
    "        try:\n",
    "            impact_data = {\n",
    "                f\"{lcia}\": {\n",
    "                    \"gwp_total\": {\n",
    "                        \"A1_A3\":{'mean': epd_impacts[x]['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'], 'unit': epd_impacts[x]['impacts'][lcia]['gwp'][\"A1A2A3\"]['unit']},\n",
    "                        \"C2\": epd_impacts[x]['impacts'][lcia]['gwp']['C2'],\n",
    "                        \"C3\": epd_impacts[x]['impacts'][lcia]['gwp']['C3'],\n",
    "                        \"C4\": epd_impacts[x]['impacts'][lcia]['gwp']['C4'],\n",
    "                        \"D1\": epd_impacts[x]['impacts'][lcia]['gwp']['D']\n",
    "                    }\n",
    "                },\n",
    "                \"characteristics\": {}\n",
    "            }\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f'Key error on json #{x} for both original and fallback LCIA')\n",
    "            error_epds.append(f'Key error on json #{x} for both original and fallback LCIA')\n",
    "\n",
    "            impact_data = {\n",
    "                \"error\": \"No valid LCIA data found\",\n",
    "                \"characteristics\": {}\n",
    "            }\n",
    "\n",
    "    # impact_data = {\n",
    "\n",
    "    #     f\"{lcia}\": {\n",
    "    #         \"gwp_total\": {\n",
    "    #         \"A1_A3\": epd_impacts[x]['impacts'][lcia]['gwp'][\"A1A2A3\"]['mean'],\n",
    "    #         \"C2\": epd_impacts[x]['impacts'][lcia]['gwp']['C2'],\n",
    "    #         \"C3\": epd_impacts[x]['impacts'][lcia]['gwp']['C3'],\n",
    "    #         \"C4\": epd_impacts[x]['impacts'][lcia]['gwp']['C4'],\n",
    "    #         \"D1\": epd_impacts[x]['impacts'][lcia]['gwp']['D']\n",
    "    #         },\n",
    "    #         # \"gwp_fossil\": {\n",
    "    #         # \"A1_A3\": 2.0,\n",
    "    #         # \"C2\": 0.1,\n",
    "    #         # \"C3\": 0.04,\n",
    "    #         # \"C4\": 0.01,\n",
    "    #         # \"D1\": -0.48\n",
    "    #         # }\n",
    "    #     },\n",
    "    #     \"characteristics\": {}\n",
    "    # }\n",
    "        \n",
    "    material_data['impacts'] = impact_data\n",
    "    # except KeyError:\n",
    "    #     print(f'Key error on json #{x}')\n",
    "    #     message = f'json {x} key error'\n",
    "    #     error_epds.append(message)\n",
    "    #     material_data.update({'characteristics':message})\n",
    "    \n",
    "    EPDs.append(material_data)\n",
    "    print(f'json #{x} is done')\n",
    "\n",
    "with open('produced_EC3_epds.json', 'w') as json_file:\n",
    "    json.dump(EPDs, json_file, indent=4)\n",
    "\n",
    "print(\"All data saved to epds.json\")\n",
    "\n",
    "with open('produced_EC3_errors.json', 'w') as json_file:\n",
    "    json.dump(error_epds, json_file, indent=4)\n",
    "\n",
    "print(\"All error data saved to epds.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'material_id': 'b03dba1dca5b49acb1a5aa4daab546b4',\n",
       "  'validity': {'gte': '2018-06-26T01:11:48.938840Z', 'lte': '2021-10-03'},\n",
       "  'display_name': 'Ready Mix',\n",
       "  'source': 'Product Specific EPDs',\n",
       "  'declared_unit': '1 m3',\n",
       "  'A4_transportation': {'mode': 'concrete mixer truck',\n",
       "   'distance': {'qty': '51.49888 km', 'unit': 'km (plchlder)'}},\n",
       "  'service_life': None,\n",
       "  'waste_rate': 'Unmapped',\n",
       "  'density': {'qty': '2400 kg / m^3', 'unit': 'kg/m3 (plchlder)'},\n",
       "  'item_mass': {'qty': '2400 kg', 'unit': 'kg (plchlder)'},\n",
       "  'impacts': {'TRACI 2.1': {'gwp_total': {'A1_A3': 339.0,\n",
       "     'C2': None,\n",
       "     'C3': None,\n",
       "     'C4': None,\n",
       "     'D': None}}}}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ec34u6kx'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#epd_data[0]['open_xpd_uuid']\n",
    "len(product_epd_ids)\n",
    "product_epd_ids[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "#ec3b6w55\n",
    "#ec36urza\n",
    "impact_info_url = \"https://openepd.buildingtransparency.org/api/epds/\"+\"ec3b6w55\"\n",
    "\n",
    "response_impact = requests.get(impact_info_url, headers=headers)\n",
    "resp = response_impact.json()\n",
    "\n",
    "file_path = 'impacts2.json'\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(resp, json_file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    material_data = {\n",
    "        \"material_id\": 'to be assigned later',\n",
    "        \"display_name\": EPDname,\n",
    "        \"source\": none,\n",
    "        \"description\": f'{desc},',\n",
    "        #\"validity\": date_validity_ends_str,\n",
    "        \"reference_pcr\": {\n",
    "            \"name\": pcr_name,\n",
    "            \"id\": pcr_id,\n",
    "            \"link\": short_link\n",
    "        },\n",
    "        \"thickness\": {\n",
    "            \"qty\": thckqty,\n",
    "            \"unit\": thckU\n",
    "        },\n",
    "        \"service_life\": seLi,\n",
    "        \"waste_rate\": none,\n",
    "        \"transportation\": {\n",
    "            \"mode\": tMode,\n",
    "            \"distance\": dist\n",
    "        },\n",
    "        \"density\": {\n",
    "            \"qty\": dens,\n",
    "            \"unit\": none\n",
    "        },\n",
    "        \"linear_density\": {\n",
    "            \"qty\": sdens,\n",
    "            \"unit\": none\n",
    "        },\n",
    "        \"declared_unit\": unit,\n",
    "        \"lcia_method\": lcia,\n",
    "        \"background_database\": none,\n",
    "        \"impacts\": {\n",
    "            \"gwp_total\": {\n",
    "                #\"A1\": A11, \"A2\": A12, \"A3\": A13, \"A4\": A14, \"A5\": A15, \"C1\": C11,\n",
    "                #\"C2\": C12, \"C3\": C13, \"C4\": C14, \"D\": D1, \"D1\": D11, \"D2\": D12\n",
    "            },\n",
    "            \"gwp_biogenic\": {\n",
    "                #\"A1\": A21, \"A2\": A22, \"A3\": A23, \"A4\": A24, \"A5\": A25, \"C1\": C21,\n",
    "                #\"C2\": C22, \"C3\": C23, \"C4\": C24, \"D\": D2, \"D1\": D21, \"D2\": D22\n",
    "            },\n",
    "            \"gwp_fossil\": {\n",
    "                #\"A1\": A31, \"A2\": A32, \"A3\": A33, \"A4\": A34, \"A5\": A35, \"C1\": C31,\n",
    "                #\"C2\": C32, \"C3\": C33, \"C4\": C34, \"D\": D3, \"D1\": D31, \"D2\": D32\n",
    "            },\n",
    "            \"gwp_iobc\": {\n",
    "                #\"A1\": A41, \"A2\": A42, \"A3\": A43, \"A4\": A44, \"A5\": A45, \"C1\": C41,\n",
    "                #\"C2\": C42, \"C3\": C43, \"C4\": C44, \"D\": D4, \"D1\": D41, \"D2\": D42\n",
    "            }\n",
    "        },\n",
    "        \"characteristics\": {}\n",
    "    },"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
